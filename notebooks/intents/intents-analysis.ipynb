{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kO9wt2g3okLS"
   },
   "source": [
    "# Análise das Intents\n",
    "\n",
    "Este jupyter-notebook vai auxiliar na análise de detecção de intenções de seu chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasa_nlu: 0.15.0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "import rasa_nlu\n",
    "print(\"rasa_nlu: {}\".format(rasa_nlu.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xeXgpdwzOAl"
   },
   "source": [
    "### Treinando o modelo do Rasa NLU\n",
    "\n",
    "* Para avaliar o bot o primeiro passo é treiner o seu chatbot. Mas não é necessário treinar a parte de conversão completa (rasa_core) apenas a parte de interpretação de mensagens (rasa_nlu).\n",
    "\n",
    "* O comando `train-nlu` do Makefile executa o treinamento apenas do `rasa_nlu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/work/coach'\n",
      "python3 -m rasa_nlu.train -c nlu_config.yml --fixed_model_name current \\\n",
      "--data data/intents/ -o /src_models --project nlu --verbose\n",
      "/usr/local/lib/python3.6/runpy.py:125: RuntimeWarning: 'rasa_nlu.train' found in sys.modules after import of package 'rasa_nlu', but prior to execution of 'rasa_nlu.train'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of data/intents/geral.md is md\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 155 (11 distinct intents)\n",
      "\t- Found intents: 'negar', 'diga_mais', 'botao', 'negacao_botao', 'afirmacao_botao', 'out_of_scope', 'negar_despedir', 'despedir', 'cumprimentar', 'tudo_bem', 'elogios'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of data/intents/aleatorio.md is md\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 411 (24 distinct intents)\n",
      "\t- Found intents: 'comida', 'de_onde_voce_eh', 'linguagens', 'genero', 'filme', 'time', 'esporte', 'signo', 'triste', 'historia', 'cor', 'bff', 'religiao', 'relationship', 'piada', 'onde_voce_mora', 'me', 'hobby', 'license', 'filhos', 'risada', 'como_estou', 'star_wars', 'playlist'\n",
      "\t- entity examples: 173 (22 distinct entities)\n",
      "\t- found entities: 'starwars', 'comida', 'filme', 'esporte', 'historia', 'bff', 'relationship', 'license', 'playlist', 'how', 'linguagens', 'genero', 'signo', 'triste', 'cor', 'where', 'piada', 'me', 'hobby', 'live', 'filhos', 'religiao'\n",
      "\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of data/intents/actions.md is md\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 6 (1 distinct intents)\n",
      "\t- Found intents: 'action_test'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 572 (36 distinct intents)\n",
      "\t- Found intents: 'negar', 'botao', 'comida', 'afirmacao_botao', 'filme', 'esporte', 'historia', 'bff', 'relationship', 'onde_voce_mora', 'despedir', 'license', 'risada', 'como_estou', 'action_test', 'star_wars', 'playlist', 'diga_mais', 'negacao_botao', 'out_of_scope', 'linguagens', 'negar_despedir', 'genero', 'cumprimentar', 'tudo_bem', 'time', 'elogios', 'signo', 'triste', 'cor', 'piada', 'me', 'hobby', 'filhos', 'de_onde_voce_eh', 'religiao'\n",
      "\t- entity examples: 173 (22 distinct entities)\n",
      "\t- found entities: 'starwars', 'comida', 'filme', 'esporte', 'historia', 'bff', 'relationship', 'license', 'playlist', 'how', 'linguagens', 'genero', 'signo', 'triste', 'cor', 'where', 'piada', 'me', 'hobby', 'live', 'filhos', 'religiao'\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:176: UserWarning: Intent 'afirmacao_botao' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "/usr/local/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:176: UserWarning: Intent 'negacao_botao' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component WhitespaceTokenizer\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-09-24 17:22:11 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CRFEntityExtractor\n",
      "2019-09-24 17:22:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-09-24 17:22:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EntitySynonymMapper\n",
      "2019-09-24 17:22:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-09-24 17:22:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component CountVectorsFeaturizer\n",
      "2019-09-24 17:22:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-09-24 17:22:13 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component EmbeddingIntentClassifier\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "2019-09-24 17:22:14 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:285: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\u001b[0m\n",
      "2019-09-24 17:22:14 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\u001b[0m\n",
      "2019-09-24 17:22:14 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/rasa_nlu/classifiers/embedding_intent_classifier.py:286: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\u001b[0m\n",
      "2019-09-24 17:22:14 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "2019-09-24 17:22:14 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-24 17:22:14 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "2019-09-24 17:22:15.213892: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-09-24 17:22:15.237246: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194975000 Hz\n",
      "2019-09-24 17:22:15.237935: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55bbc2f03380 executing computations on platform Host. Devices:\n",
      "2019-09-24 17:22:15.238015: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-09-24 17:22:15 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|██████████| 300/300 [00:32<00:00,  9.19it/s, loss=0.062, acc=1.000]\n",
      "2019-09-24 17:22:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Finished training embedding classifier, loss=0.062, train accuracy=1.000\n",
      "2019-09-24 17:22:47 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-09-24 17:22:48 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Successfully saved model into '/src_models/nlu/current'\n",
      "2019-09-24 17:22:48 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Finished training\n",
      "make: Leaving directory '/work/coach'\n"
     ]
    }
   ],
   "source": [
    "!make train-nlu -C $COACH_DIR_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos de avaliação do chatbot\n",
    "\n",
    "* O Rasa fornece vários métodos de avaliação e validação das `intents`, para verificar como utiliza-los, cada método fornece um log, imagem, gráfico ou arquivo com dados relevantes para interpretação do chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O comando `!python -m rasa_nlu.test` é a base para a avaliação do chatbot.\n",
    "\n",
    "* Na célula abaixo a flag `-h` foi utilizada para mostrar as funções e a forma de uso de cada uma delas, mude seus valores e flags para ter as informações desejadas na sua análise.\n",
    "\n",
    "* Atualmente o Rasa possui 2 modos, `evaluation` e `crossvalidation` que tem seções decicadas a eles neste jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/runpy.py:125: RuntimeWarning: 'rasa_nlu.test' found in sys.modules after import of package 'rasa_nlu', but prior to execution of 'rasa_nlu.test'; this may result in unpredictable behaviour\r\n",
      "  warn(RuntimeWarning(msg))\r\n",
      "usage: test.py [-h] [--debug] [-v] -d DATA [--mode MODE] [-c CONFIG]\r\n",
      "               [-m MODEL] [-f FOLDS] [--report [REPORT]]\r\n",
      "               [--successes [SUCCESSES]] [--errors ERRORS]\r\n",
      "               [--histogram HISTOGRAM] [--confmat CONFMAT]\r\n",
      "\r\n",
      "evaluate a Rasa NLU pipeline with cross validation or on external data\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --debug               Print lots of debugging statements. Sets logging level\r\n",
      "                        to DEBUG\r\n",
      "  -v, --verbose         Be verbose. Sets logging level to INFO\r\n",
      "  -d DATA, --data DATA  file containing training/evaluation data\r\n",
      "  --mode MODE           evaluation|crossvalidation (evaluate pretrained model\r\n",
      "                        or train model by crossvalidation)\r\n",
      "  -c CONFIG, --config CONFIG\r\n",
      "                        model configuration file (crossvalidation only)\r\n",
      "  -m MODEL, --model MODEL\r\n",
      "                        path to model (evaluation only)\r\n",
      "  -f FOLDS, --folds FOLDS\r\n",
      "                        number of CV folds (crossvalidation only)\r\n",
      "  --report [REPORT]     output path to save the intent/entitymetrics report\r\n",
      "  --successes [SUCCESSES]\r\n",
      "                        output path to save successful predictions\r\n",
      "  --errors ERRORS       output path to save model errors\r\n",
      "  --histogram HISTOGRAM\r\n",
      "                        output path for the confidence histogram\r\n",
      "  --confmat CONFMAT     output path for the confusion matrix plot\r\n"
     ]
    }
   ],
   "source": [
    "!python -m rasa_nlu.test -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O comando abaixo gera informações relevates para a validação das `intents` são elas:\n",
    "    * Matriz de confusão\n",
    "    * Histograma\n",
    "    * Erros de intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'erros.json': No such file or directory\n",
      "/usr/local/lib/python3.6/runpy.py:125: RuntimeWarning: 'rasa_nlu.test' found in sys.modules after import of package 'rasa_nlu', but prior to execution of 'rasa_nlu.test'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "2019-09-24 17:23:28.956107: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-09-24 17:23:28.981126: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194975000 Hz\n",
      "2019-09-24 17:23:28.981805: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55b8876175f0 executing computations on platform Host. Devices:\n",
      "2019-09-24 17:23:28.981881: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-09-24 17:23:29 \u001b[1;30mWARNING \u001b[0m \u001b[34mtensorflow\u001b[0m  - \u001b[33mFrom /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\u001b[0m\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mtensorflow\u001b[0m  - Restoring parameters from /models/nlu/current/component_4_EmbeddingIntentClassifier.ckpt\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../coach/data/intents/geral.md is md\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 155 (11 distinct intents)\n",
      "\t- Found intents: 'afirmacao_botao', 'despedir', 'out_of_scope', 'diga_mais', 'negar_despedir', 'elogios', 'negacao_botao', 'cumprimentar', 'botao', 'tudo_bem', 'negar'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../coach/data/intents/aleatorio.md is md\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 411 (24 distinct intents)\n",
      "\t- Found intents: 'esporte', 'risada', 'genero', 'triste', 'cor', 'me', 'onde_voce_mora', 'filhos', 'historia', 'filme', 'piada', 'religiao', 'relationship', 'time', 'linguagens', 'playlist', 'comida', 'de_onde_voce_eh', 'como_estou', 'star_wars', 'signo', 'hobby', 'bff', 'license'\n",
      "\t- entity examples: 173 (22 distinct entities)\n",
      "\t- found entities: 'starwars', 'triste', 'religiao', 'where', 'relationship', 'linguagens', 'playlist', 'comida', 'signo', 'license', 'how', 'esporte', 'cor', 'genero', 'me', 'filhos', 'historia', 'filme', 'piada', 'live', 'bff', 'hobby'\n",
      "\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of ../../coach/data/intents/actions.md is md\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 6 (1 distinct intents)\n",
      "\t- Found intents: 'action_test'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 572 (36 distinct intents)\n",
      "\t- Found intents: 'triste', 'onde_voce_mora', 'diga_mais', 'action_test', 'tudo_bem', 'religiao', 'relationship', 'afirmacao_botao', 'time', 'linguagens', 'playlist', 'comida', 'negar_despedir', 'de_onde_voce_eh', 'star_wars', 'signo', 'license', 'esporte', 'risada', 'genero', 'cor', 'despedir', 'me', 'filhos', 'elogios', 'negacao_botao', 'cumprimentar', 'filme', 'botao', 'historia', 'piada', 'negar', 'out_of_scope', 'como_estou', 'hobby', 'bff'\n",
      "\t- entity examples: 173 (22 distinct entities)\n",
      "\t- found entities: 'starwars', 'triste', 'religiao', 'where', 'relationship', 'linguagens', 'playlist', 'comida', 'signo', 'license', 'how', 'esporte', 'cor', 'genero', 'me', 'filhos', 'historia', 'filme', 'piada', 'live', 'bff', 'hobby'\n",
      "\n",
      "2019-09-24 17:23:29 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Running model for predictions:\n",
      "100%|████████████████████████████████████████| 572/572 [00:01<00:00, 406.74it/s]\n",
      "2019-09-24 17:23:30 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Intent evaluation results:\n",
      "2019-09-24 17:23:30 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Intent Evaluation: Only considering those 572 examples that have a defined intent out of 572 examples\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "2019-09-24 17:23:30 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - F1-Score:  0.9991045539826028\n",
      "2019-09-24 17:23:30 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Precision: 1.0\n",
      "2019-09-24 17:23:30 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Accuracy:  0.9982517482517482\n",
      "2019-09-24 17:23:30 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "                      0.00      0.00      0.00         0\n",
      "    action_test       1.00      1.00      1.00         6\n",
      "afirmacao_botao       1.00      1.00      1.00         1\n",
      "            bff       1.00      1.00      1.00        15\n",
      "          botao       1.00      1.00      1.00         3\n",
      "         comida       1.00      1.00      1.00        16\n",
      "     como_estou       1.00      1.00      1.00        15\n",
      "            cor       1.00      1.00      1.00        13\n",
      "   cumprimentar       1.00      1.00      1.00        18\n",
      "de_onde_voce_eh       1.00      1.00      1.00        14\n",
      "       despedir       1.00      1.00      1.00        20\n",
      "      diga_mais       1.00      1.00      1.00         9\n",
      "        elogios       1.00      1.00      1.00        27\n",
      "        esporte       1.00      1.00      1.00        20\n",
      "         filhos       1.00      1.00      1.00        15\n",
      "          filme       1.00      1.00      1.00        13\n",
      "         genero       1.00      1.00      1.00        23\n",
      "       historia       1.00      1.00      1.00        15\n",
      "          hobby       1.00      1.00      1.00        19\n",
      "        license       1.00      1.00      1.00        15\n",
      "     linguagens       1.00      0.95      0.98        21\n",
      "             me       1.00      1.00      1.00        19\n",
      "  negacao_botao       1.00      1.00      1.00         1\n",
      "          negar       1.00      1.00      1.00        11\n",
      " negar_despedir       1.00      1.00      1.00        31\n",
      " onde_voce_mora       1.00      1.00      1.00        14\n",
      "   out_of_scope       1.00      1.00      1.00        11\n",
      "          piada       1.00      1.00      1.00        12\n",
      "       playlist       1.00      1.00      1.00        18\n",
      "   relationship       1.00      1.00      1.00        28\n",
      "       religiao       1.00      1.00      1.00        24\n",
      "         risada       1.00      1.00      1.00        19\n",
      "          signo       1.00      1.00      1.00         9\n",
      "      star_wars       1.00      1.00      1.00        22\n",
      "           time       1.00      1.00      1.00        14\n",
      "         triste       1.00      1.00      1.00        18\n",
      "       tudo_bem       1.00      1.00      1.00        23\n",
      "\n",
      "      micro avg       1.00      1.00      1.00       572\n",
      "      macro avg       0.97      0.97      0.97       572\n",
      "   weighted avg       1.00      1.00      1.00       572\n",
      "\n",
      "2019-09-24 17:23:30 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Model prediction errors saved to errors.json.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-24 17:23:31 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Confusion matrix, without normalization: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  6  0 ...  0  0  0]\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 14  0  0]\n",
      " [ 0  0  0 ...  0 18  0]\n",
      " [ 0  0  0 ...  0  0 23]]\n",
      "Figure(2000x2000)\n",
      "Figure(1000x1000)\n",
      "2019-09-24 17:23:37 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Entity evaluation results:\n",
      "2019-09-24 17:23:37 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Evaluation for entity extractor: CRFEntityExtractor \n",
      "2019-09-24 17:23:37 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - F1-Score:  0.9834805875697924\n",
      "2019-09-24 17:23:37 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Precision: 0.9850944086096524\n",
      "2019-09-24 17:23:37 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Accuracy:  0.9845869297163995\n",
      "2019-09-24 17:23:37 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bff       1.00      1.00      1.00        17\n",
      "      comida       1.00      1.00      1.00        17\n",
      "         cor       1.00      1.00      1.00        13\n",
      "     esporte       1.00      1.00      1.00         6\n",
      "      filhos       1.00      1.00      1.00        11\n",
      "       filme       0.80      1.00      0.89         4\n",
      "      genero       1.00      1.00      1.00        16\n",
      "    historia       1.00      0.83      0.91         6\n",
      "       hobby       1.00      0.45      0.62        11\n",
      "         how       1.00      0.88      0.93        24\n",
      "     license       1.00      0.86      0.92        14\n",
      "  linguagens       1.00      1.00      1.00        14\n",
      "        live       1.00      1.00      1.00        13\n",
      "          me       1.00      1.00      1.00         6\n",
      "   no_entity       0.99      1.00      0.99      1385\n",
      "       piada       0.78      1.00      0.88         7\n",
      "    playlist       0.88      1.00      0.93         7\n",
      "relationship       1.00      0.89      0.94         9\n",
      "    religiao       0.94      1.00      0.97        16\n",
      "       signo       1.00      1.00      1.00         3\n",
      "    starwars       0.91      0.77      0.83        13\n",
      "      triste       1.00      0.86      0.92         7\n",
      "       where       1.00      0.33      0.50         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1622\n",
      "   macro avg       0.97      0.91      0.92      1622\n",
      "weighted avg       0.99      0.98      0.98      1622\n",
      "\n",
      "2019-09-24 17:23:37 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Finished evaluation\n"
     ]
    }
   ],
   "source": [
    "!rm erros.json\n",
    "!python -m rasa_nlu.test -d $COACH_INTENTS_PATH -m $COACH_MODELS_NLU_PATH --mode evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Confusão\n",
    "* A matriz de confusão mostra a correlação entre as intents.\n",
    "* A diagonal principal tem forte correlação pois mostra a relação de uma intent **com ela mesma**\n",
    "* O ideal é que não haja **nenhum valor** diferente de **0 fora da diagonal principal**.\n",
    "\n",
    "`Execute este notebook no Firefox para visualizar o PDF da matriz de confusão`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"700\"\n",
       "            src=\"./confmat.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4f44159dd8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./confmat.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erros\n",
    "* O arquivo `erros,json` mostra os erros encontrados. Este arquivo lista os mesmos erros mostrados na **matriz de confusão**, então caso ela fique muito grande, não se preocupe, pois você pode apenas procurar os erros no arquivo gerado.\n",
    "* Os erros mostrados são textos repetidos nos exemplos de diferrentes `intents`.\n",
    "* Caso o arquivo não seja gerado significa que não foram encontrados erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "    {\r\n",
      "        \"text\": \"e o c#\",\r\n",
      "        \"intent\": \"linguagens\",\r\n",
      "        \"intent_prediction\": {\r\n",
      "            \"name\": \"\",\r\n",
      "            \"confidence\": 0.0\r\n",
      "        }\r\n",
      "    }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "%cat errors.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograma\n",
    "\n",
    "* O histograma contém a distribuição da predições das `intents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"700\"\n",
       "            src=\"./hist.png\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4f44159f28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./hist.png', width=900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências:\n",
    "\n",
    "O Rasa está em constante evolução, alguns links úteis para a construção deste jupyter-notebook e para a análise das `intents` são:\n",
    "\n",
    "* [Evaluation](https://rasa.com/docs/nlu/evaluation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "y4miuS-TqYcn",
    "BBF6Nqi9scQE",
    "Fs3nOUzBsqrG",
    "5MnGuFRpzzBh"
   ],
   "default_view": {},
   "name": "Building a Simple Bot with Rasa Stack - Tutorial",
   "provenance": [
    {
     "file_id": "1GutDkDXmfU-nRzNH7Pxxx8YpdvLUw9LO",
     "timestamp": 1521183725373
    }
   ],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
